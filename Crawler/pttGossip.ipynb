{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先寫一個簡單版的ptt爬蟲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\udic\\documents\\htdocs\\publictutorial\\venv\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file c:\\users\\udic\\appdata\\local\\programs\\python\\python35\\Lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = []\n",
    "for page in range(25675, 25676):\n",
    "    res = requests.get('https://www.ptt.cc/bbs/Gossiping/index.html', cookies={'over18': '1'})\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    \n",
    "    for j in soup.select('.title a'):\n",
    "        res = requests.get('https://www.ptt.cc' + j['href'], cookies={'over18': '1'})\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        data.append({'title':j.text, 'url':'https://www.ptt.cc' + j['href'], 'text':soup.select('#main-content')[0].text})\n",
    "\n",
    "json.dump(data, open('ptt.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 困難版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\udic\\documents\\htdocs\\publictutorial\\venv\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file c:\\users\\udic\\appdata\\local\\programs\\python\\python35\\Lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "c:\\users\\udic\\documents\\htdocs\\publictutorial\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "c:\\users\\udic\\documents\\htdocs\\publictutorial\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "c:\\users\\udic\\documents\\htdocs\\publictutorial\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "c:\\users\\udic\\documents\\htdocs\\publictutorial\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "c:\\users\\udic\\documents\\htdocs\\publictutorial\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "def parse(link, timeout=3):\n",
    "    resp = requests.get(url=link, cookies={'over18': '1'}, verify=False, timeout=timeout)\n",
    "    if resp.status_code != 200:\n",
    "        return json.dumps({\"error\": \"invalid url\"}, sort_keys=True, ensure_ascii=False)\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    main_content = soup.find(id=\"main-content\")\n",
    "    metas = main_content.select('div.article-metaline')\n",
    "    title = ''\n",
    "    if metas:\n",
    "        title = metas[1].select('span.article-meta-value')[0].string if metas[1].select('span.article-meta-value')[0] else title\n",
    "\n",
    "    # remove and keep push nodes\n",
    "    pushes = main_content.find_all('div', class_='push')\n",
    "    for push in pushes:\n",
    "        push.extract()\n",
    "\n",
    "    # 移除 '※ 發信站:' (starts with u'\\u203b'), '◆ From:' (starts with u'\\u25c6'), 空行及多餘空白\n",
    "    # 保留英數字, 中文及中文標點, 網址, 部分特殊符號\n",
    "    filtered = [ v for v in main_content.stripped_strings if v[0] not in [u'※', u'◆'] and v[:2] not in [u'--'] ]\n",
    "    expr = re.compile(r'[^\\u4e00-\\u9fa5\\u3002\\uff1b\\uff0c\\uff1a\\u201c\\u201d\\uff08\\uff09\\u3001\\uff1f\\u300a\\u300b\\s\\w:/-_.?~%()]')\n",
    "    for i in range(len(filtered)):\n",
    "        filtered[i] = re.sub(expr, '', filtered[i])\n",
    "\n",
    "    filtered = [_f for _f in filtered if _f]  # remove empty strings\n",
    "    content = ' '.join(filtered)\n",
    "    content = re.sub(r'(\\s)+', ' ', content)\n",
    "\n",
    "    # push messages\n",
    "    p, b, n = 0, 0, 0\n",
    "    messages = []\n",
    "    for push in pushes:\n",
    "        if not push.find('span', 'push-tag'):\n",
    "            continue\n",
    "        push_tag = push.find('span', 'push-tag').string.strip(' \\t\\n\\r')\n",
    "        push_userid = push.find('span', 'push-userid').string.strip(' \\t\\n\\r')\n",
    "        # if find is None: find().strings -> list -> ' '.join; else the current way\n",
    "        push_content = push.find('span', 'push-content').strings\n",
    "        push_content = ' '.join(push_content)[1:].strip(' \\t\\n\\r')  # remove ':'\n",
    "        push_ipdatetime = push.find('span', 'push-ipdatetime').string.strip(' \\t\\n\\r')\n",
    "        messages.append( {'push_tag': push_tag, 'push_userid': push_userid, 'push_content': push_content, 'push_ipdatetime': push_ipdatetime} )\n",
    "        if push_tag == u'推':\n",
    "            p += 1\n",
    "        elif push_tag == u'噓':\n",
    "            b += 1\n",
    "        else:\n",
    "            n += 1\n",
    "\n",
    "    # json data\n",
    "    data = {\n",
    "        'article_title': title,\n",
    "        'content': content,\n",
    "        'messages': messages\n",
    "    }\n",
    "    return data\n",
    "\n",
    "import requests, json, re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = []\n",
    "for page in range(25675, 25676):\n",
    "    res = requests.get('https://www.ptt.cc/bbs/Gossiping/index.html', cookies={'over18': '1'})\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    \n",
    "    for j in soup.select('.title a'):\n",
    "        res = requests.get('https://www.ptt.cc' + j['href'], cookies={'over18': '1'})\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        data.append(parse('https://www.ptt.cc' + j['href']))\n",
    "\n",
    "json.dump(data, open('ptt.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
