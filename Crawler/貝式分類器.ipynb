{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 貝氏分類器\n",
    "\n",
    "#### 理論\n",
    "\n",
    "貝氏定理就是我們熟知的條件機率  \n",
    "\n",
    "首先呢：\n",
    "![img](貝氏1.png)\n",
    "\n",
    "倒過來也一樣\n",
    "![img](貝氏2.png)\n",
    "\n",
    "所以兩式個關係是這樣：\n",
    "![img](貝氏3.png)\n",
    "\n",
    "這個關係式，可以用於分類上面  \n",
    "該公式解釋成白話文，意思是：\n",
    "1. 如果有出現這些字，讓他屬於某一類別的機率 == （該類別底下，有出現這些字的機率）* 該類別出現的機率 / 出現這些字的機率\n",
    "![img](貝氏4.png)\n",
    "\n",
    "### 問題是...\n",
    "\n",
    "<mark style='color:red'>該類別底下，有出現這些字的機率</mark>  \n",
    "e.q. 請計算負面句子當中，同時出現好棒棒、廠廠、三寶、酸民的機率  \n",
    "若訓練資料裏面，沒有同時出現 <mark style='color:red'>好棒棒、廠廠、三寶、酸民</mark>的句子  \n",
    "那他屬於負面句子的機率是0  \n",
    "正面的句子也是0（我不相信正面句子會講什麼三寶）  \n",
    "最後判斷會淪為猜測（導致準確度趨近0.5）  \n",
    "\n",
    "![img](naiveB.png)\n",
    "![img](naiveB1.png)\n",
    "\n",
    "所以如果我們拿掉 <mark style='color:red'>同時出現</mark>這個constraint呢？</mark>  \n",
    "假設這些字出現的機率為獨立事件  \n",
    "則我們可以將公式改寫成\n",
    "![img](naiveB2.png)\n",
    "![img](naiveB3.png)\n",
    "\n",
    "這就是今天所使用的 NaiveBayes \n",
    "\n",
    "首先要先自制兩個函式  \n",
    "會幫我們對資料進行前處理\n",
    "1. create_Mainfeatures：\n",
    "    * 將正面與反正資料串在一起\n",
    "    * 計算每個單字出現的頻率\n",
    "    * 利用卡方公式，如果該單字經常出現在正面文集或是負面文集，就是情緒性的單字\n",
    "    * 將情緒性的單字集成字典並回傳 -> 就是 bestMainFeatures\n",
    "2. CutAndrmStopWords：\n",
    "    * 輸入一個句子\n",
    "    * 使用結巴斷詞\n",
    "    * 也移除stopwords\n",
    "    * 將結果回傳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools, pickle, json, sys\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "\n",
    "def create_Mainfeatures(pos_data, neg_data, BestFeatureVec):\n",
    "    posWords = list(itertools.chain(*pos_data)) #把多為數組解煉成一維數組\n",
    "    negWords = list(itertools.chain(*neg_data)) #同理\n",
    "\n",
    "    # bigram\n",
    "    bigram_finder = BigramCollocationFinder.from_words(posWords)\n",
    "    posBigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 5000)\n",
    "    bigram_finder = BigramCollocationFinder.from_words(negWords)\n",
    "    negBigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 5000)\n",
    "    posWords += posBigrams #詞和雙詞搭配\n",
    "    negWords += negBigrams\n",
    "\n",
    "    word_fd = FreqDist() #可統計所有詞的詞頻\n",
    "    cond_word_fd = ConditionalFreqDist() #可統計積極文本中的詞頻和消極文本中的詞頻\n",
    "    for word in posWords:\n",
    "        word_fd[word] += 1\n",
    "        cond_word_fd['pos'][word] += 1\n",
    "    for word in negWords:\n",
    "        word_fd[word] += 1\n",
    "        cond_word_fd['neg'][word] += 1\n",
    "\n",
    "    pos_word_count = cond_word_fd['pos'].N() #積極詞的數量\n",
    "    neg_word_count = cond_word_fd['neg'].N() #消極詞的數量\n",
    "    total_word_count = pos_word_count + neg_word_count\n",
    "\n",
    "    word_features = {}\n",
    "    for word, freq in word_fd.items():\n",
    "        pos_score = BigramAssocMeasures.chi_sq(cond_word_fd['pos'][word], (freq, pos_word_count), total_word_count) #計算積極詞的卡方統計量，這裏也可以計算互信息等其它統計量\n",
    "        neg_score = BigramAssocMeasures.chi_sq(cond_word_fd['neg'][word], (freq, neg_word_count), total_word_count) #同理\n",
    "        word_features[word] = pos_score + neg_score\n",
    "\n",
    "    def find_best_words(number):\n",
    "        best = sorted(word_features.items(), key=lambda x: -x[1])[:number] # 把詞按信息量倒序排序。number 是特徵的微度，式可以不斷調整至最優的\n",
    "        return set(w for w, s in best)\n",
    "\n",
    "    best = find_best_words(BestFeatureVec)\n",
    "    pickle.dump(best, open('bestMainFeatures.pickle.{}'.format(BestFeatureVec), 'wb'))\n",
    "    return best\n",
    "\n",
    "import jieba.posseg as pseg\n",
    "import jieba, os\n",
    "\n",
    "BASEDIR = os.path.dirname('.')\n",
    "stopwords = json.load(open(os.path.join(BASEDIR, 'stopwords', 'stopwords.json'), 'r'))\n",
    "jieba.load_userdict(os.path.join(BASEDIR, 'dictionary', 'dict.txt.big.txt'))\n",
    "jieba.load_userdict(os.path.join(BASEDIR, \"dictionary\", \"NameDict_Ch_v2\"))\n",
    "def CutAndrmStopWords(sentence):\n",
    "    def condition(x):\n",
    "        x = list(x)\n",
    "        word, flag = x[0], x[1]\n",
    "        if len(word) > 1 and flag!='eng' and flag != 'm' and flag !='mq' and word not in stopwords:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    result = filter(condition, pseg.cut(sentence))\n",
    "    result = map(lambda x:list(x)[0], result)\n",
    "    return list(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類器的演算法\n",
    "\n",
    "建立一個叫作swinger的類別  \n",
    "以下解釋函式功能\n",
    "1. load函式：\n",
    "    * 把訓練資料載入\n",
    "    * 透過前面建立好的create_Mainfeatures，從訓練資料中找出最好的情緒字典，best main features\n",
    "    * 透過bestMainFeatures，把訓練資料的句字去蕪存菁，再送入分類器做訓練\n",
    "2. buildTestData：\n",
    "    * 將測試資料去蕪存菁\n",
    "3. best_Mainfeatures：\n",
    "    * 使用bestMainFeatures，將句子去蕪存菁的函式\n",
    "4. score：\n",
    "    * 用測試資料去算準確度\n",
    "5. swing：\n",
    "    * 分類的api，給一句話，他會依據模型去判斷pos或是neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import nltk, json, pickle, sys, collections, jieba, os\n",
    "from random import shuffle\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure, log_likelihood, approxrand)\n",
    "\n",
    "\n",
    "class Swinger(object):\n",
    "    \"\"\"docstring for Swinger\"\"\"\n",
    "    classifier_table = {\n",
    "        'MultinomialNB':MultinomialNB(),\n",
    "        'BernoulliNB':BernoulliNB(),\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train = []\n",
    "        self.test = []\n",
    "        self.classifier = ''\n",
    "\n",
    "    def load(self, model, pos, neg, BestFeatureVec=700):\n",
    "        BestFeatureVec = int(BestFeatureVec)\n",
    "\n",
    "        print('load bestMainFeatures failed!!\\nstart creating bestMainFeatures ...')\n",
    "\n",
    "        self.pos_origin = json.load(open(pos, 'r'))\n",
    "        self.neg_origin = json.load(open(neg, 'r'))\n",
    "        shuffle(self.pos_origin)\n",
    "        shuffle(self.neg_origin)\n",
    "        poslen = len(self.pos_origin)\n",
    "        neglen = len(self.neg_origin)\n",
    "\n",
    "        # build train and test data.\n",
    "        self.pos_review = self.pos_origin[:int(poslen*0.9)]\n",
    "        self.pos_test = self.pos_origin[int(poslen*0.9):]\n",
    "        self.neg_review = self.neg_origin[:int(neglen*0.9)]\n",
    "        self.neg_test = self.neg_origin[int(neglen*0.9):]\n",
    "\n",
    "        self.bestMainFeatures = create_Mainfeatures(pos_data=self.pos_review, neg_data=self.neg_review, BestFeatureVec=BestFeatureVec) # 使用詞和雙詞搭配作為特徵\n",
    "        print(self.bestMainFeatures)\n",
    "        # build model\n",
    "        print('start building {} model!!!'.format(model))\n",
    "\n",
    "        self.classifier = SklearnClassifier(self.classifier_table[model]) #nltk在sklearn的接口\n",
    "        if len(self.train) == 0:\n",
    "            print('build training data')\n",
    "            posFeatures = self.emotion_features(self.best_Mainfeatures, self.pos_review, 'pos')\n",
    "            negFeatures = self.emotion_features(self.best_Mainfeatures, self.neg_review, 'neg')\n",
    "            self.train = posFeatures + negFeatures\n",
    "        self.classifier.train(self.train) #訓練分類器\n",
    "        pickle.dump(self.classifier, open('{}.pickle.{}'.format(model, BestFeatureVec),'wb'))\n",
    "\n",
    "    def buildTestData(self, pos_test, neg_test):\n",
    "        pos_test = json.load(open(pos_test, 'r'))\n",
    "        neg_test = json.load(open(neg_test, 'r'))\n",
    "        posFeatures = self.emotion_features(self.best_Mainfeatures, pos_test, 'pos')\n",
    "        negFeatures = self.emotion_features(self.best_Mainfeatures, neg_test, 'neg')\n",
    "        return posFeatures + negFeatures\n",
    "\n",
    "    def best_Mainfeatures(self, word_list):\n",
    "        return {word:True for word in word_list if word in self.bestMainFeatures}\n",
    "\n",
    "    def score(self, pos_test, neg_test):\n",
    "        from sklearn.metrics import precision_recall_curve\n",
    "        from sklearn.metrics import roc_curve\n",
    "        from sklearn.metrics import auc\n",
    "        # build test data set\n",
    "        if len(self.test) == 0:\n",
    "            self.test = self.buildTestData(pos_test, neg_test)\n",
    "\n",
    "        test, test_tag = zip(*self.test)\n",
    "        pred = list(map(lambda x:1 if x=='pos' else 0, self.classifier.classify_many(test))) #對開發測試集的數據進行分類，給出預測的標籤\n",
    "        tag = list(map(lambda x:1 if x=='pos' else 0, test_tag))\n",
    "        # ROC AUC\n",
    "        fpr, tpr, _ = roc_curve(tag, pred, pos_label=1)\n",
    "        print(\"ROC AUC:\" + str(auc(fpr, tpr)))\n",
    "        return auc(fpr, tpr)\n",
    "\n",
    "    def emotion_features(self, feature_extraction_method, data, emo):\n",
    "        return list(map(lambda x:[feature_extraction_method(x), emo], data)) #爲積極文本賦予\"pos\"\n",
    "\n",
    "    def swing(self, sentence):\n",
    "        sentence = self.best_Mainfeatures(CutAndrmStopWords(sentence))\n",
    "        return self.classifier.classify(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB V.S. BernoulliNB\n",
    "都是Naive Bayes的一種  \n",
    "差異在於：\n",
    "1. Multinomial 會計算該單字出現再該類別幾次\n",
    "2. Bernoulli 只是計算該單字出現與否而已\n",
    "\n",
    "通常Multinomial會更適合用在Text classification上面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load bestMainFeatures failed!!\n",
      "start creating bestMainFeatures ...\n",
      "{'完全', '酒店', '板主', '南部', '律師', '噁心', '亂源', '父母', '這種', '社會'}\n",
      "start building MultinomialNB model!!!\n",
      "build training data\n",
      "ROC AUC:0.608679883946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.60867988394584138"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Swinger()\n",
    "s.load('MultinomialNB', pos='MyPos.json', neg='MyNeg.json', BestFeatureVec=10)\n",
    "s.score(pos_test='MyPos.json', neg_test='MyNeg.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.swing('大停電的夜晚，我很幸運看到了星空')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.swing('XXX 停電害我不能打電動拉')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load bestMainFeatures failed!!\n",
      "start creating bestMainFeatures ...\n"
     ]
    }
   ],
   "source": [
    "s = Swinger()\n",
    "s.load('MultinomialNB', pos='pos.json', neg='neg.json', BestFeatureVec=50)\n",
    "s.score(pos_test='pos.json', neg_test='neg.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.swing('大停電的夜晚，我很幸運看到了星空')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.swing('XXX 停電害我不能打電動拉')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的feature數量對準確度的影響?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "multi = []\n",
    "bernou = []\n",
    "for num in range(10, 50, 10):\n",
    "    s = Swinger()\n",
    "    s.load('MultinomialNB', pos='pos.json', neg='neg.json', BestFeatureVec=num)\n",
    "    multi.append(s.score(pos_test='pos.json', neg_test='neg.json'))\n",
    "    \n",
    "    s.load('BernoulliNB', pos='pos.json', neg='neg.json', BestFeatureVec=num)\n",
    "    bernou.append(s.score(pos_test='pos.json', neg_test='neg.json'))\n",
    "\n",
    "plt.plot(range(10, 50, 10), multi, 'o-', color=\"y\",label=\"Multinomial\")\n",
    "plt.plot(range(10, 50, 10), bernou, 'o-', color=\"r\",label=\"Bernoulli\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"features vectors\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
