{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis (文本情緒分析)\n",
    "## 情緒意見分析是利用自然語言處理、文本分析以及語意特性來決定句子、文章甚至文本的主觀訊息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類器標準架構\n",
    "引入機器學習模型，來教會電腦判斷情緒"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.nltk.org/images/supervised-classification.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dropbox.com/s/kxhf5eadds2jmzq/senti.png?dl=1\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.python-course.eu/images/supervised_learning.png\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最常見的分類器\n",
    "## 貝氏分類器 (Naive Bayes classifiers)\n",
    "\n",
    "###  基本理論：貝氏定理\n",
    "\n",
    "就是我們熟知的條件機率  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dropbox.com/s/9mwjf5h3e9o2bqx/bayes.png?dl=1\" width=\"200\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個關係式，可以用於分類上面  \n",
    "該公式解釋成白話文，意思是：\n",
    "如果有出現這些字，其屬於某一類別的機率 == （該類別底下，有出現這些字的機率）* 該類別出現的機率 / 出現這些字的機率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dropbox.com/s/o9xwjo4a2c5gk7j/nb2.png?dl=1\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 為何我們稱之為 Naive\n",
    "\n",
    "### 問題是...\n",
    "\n",
    "<mark style='color:red'>該類別底下，有出現這些字的機率</mark>  \n",
    "e.q. 請計算負面句子當中，同時出現好棒棒、廠廠、三寶、酸民的機率  \n",
    "若訓練資料裏面，沒有同時出現 <mark style='color:red'>好棒棒、廠廠、三寶、酸民</mark>的句子  \n",
    "那他屬於負面句子的機率是0  \n",
    "正面的句子也是0（我不相信正面句子會講什麼三寶）  \n",
    "最後判斷會淪為猜測（導致準確度趨近0.5）  \n",
    "\n",
    "引入Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dropbox.com/s/qyw4bcw22muz5c7/nb3.png?dl=1\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dropbox.com/s/9s7gtuj6568efht/nb4.png?dl=1\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實作重點 (特徵擷取)\n",
    "#### create_Mainfeatures： 卡方的計算\n",
    "    * 將正面與反正資料串在一起\n",
    "    * 計算每個單字出現的頻率\n",
    "    * 利用卡方公式，如果該單字經常出現在正面文集或是負面文集，就是情緒性的單字\n",
    "    * 將情緒性的單字集成字典並回傳 -> 就是 bestMainFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools, pickle, json, sys\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "\n",
    "def create_Mainfeatures(pos_data, neg_data, BestFeatureVec, chi_sq):\n",
    "    posWords = list(itertools.chain(*pos_data)) \n",
    "    negWords = list(itertools.chain(*neg_data)) \n",
    "\n",
    "    word_fd = FreqDist() \n",
    "    cond_word_fd = ConditionalFreqDist() \n",
    "    for word in posWords:\n",
    "        word_fd[word] += 1\n",
    "        cond_word_fd['pos'][word] += 1\n",
    "    for word in negWords:\n",
    "        word_fd[word] += 1\n",
    "        cond_word_fd['neg'][word] += 1\n",
    "\n",
    "    pos_word_count = cond_word_fd['pos'].N() \n",
    "    neg_word_count = cond_word_fd['neg'].N() \n",
    "    total_word_count = pos_word_count + neg_word_count\n",
    "\n",
    "    word_features = {}\n",
    "    for word, freq in word_fd.items():\n",
    "        if chi_sq==True:\n",
    "            pos_score = BigramAssocMeasures.chi_sq(cond_word_fd['pos'][word], (freq, pos_word_count), total_word_count) \n",
    "            neg_score = BigramAssocMeasures.chi_sq(cond_word_fd['neg'][word], (freq, neg_word_count), total_word_count) \n",
    "        else:\n",
    "            pos_score = freq\n",
    "            neg_score = freq\n",
    "        word_features[word] = pos_score + neg_score\n",
    "\n",
    "    def find_best_words(number):\n",
    "        best = sorted(word_features.items(), key=lambda x: -x[1])[:number]\n",
    "        return set(w for w, s in best)\n",
    "\n",
    "    best = find_best_words(BestFeatureVec)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_Mainfeatures(pos_data=json.load(open(\"pos.json\", 'r')), neg_data=json.load(open(\"neg.json\", 'r')), BestFeatureVec=10, chi_sq=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類器的演算法\n",
    "\n",
    "建立一個叫作swinger的類別  \n",
    "以下解釋函式功能\n",
    "1. load函式：\n",
    "    * 把訓練資料載入\n",
    "    * 透過前面建立好的create_Mainfeatures，從訓練資料中找出最好的情緒字典，best main features\n",
    "    * 透過bestMainFeatures，把訓練資料的句字去蕪存菁，再送入分類器做訓練\n",
    "2. buildTestData：\n",
    "    * 將測試資料去蕪存菁\n",
    "3. best_Mainfeatures：\n",
    "    * 使用bestMainFeatures，將句子去蕪存菁的函式\n",
    "4. score：\n",
    "    * 用測試資料去算準確度\n",
    "5. swing：\n",
    "    * 分類的api，給一句話，他會依據模型去判斷pos或是neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import nltk, json, pickle, sys, collections, jieba, os\n",
    "from random import shuffle\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure, log_likelihood, approxrand)\n",
    "\n",
    "\n",
    "class Swinger(object):\n",
    "    \"\"\"docstring for Swinger\"\"\"\n",
    "    classifier_table = {\n",
    "        'MultinomialNB':MultinomialNB(),\n",
    "        'BernoulliNB':BernoulliNB(),\n",
    "    }\n",
    "    \n",
    "    def __init__(self, chi_sq):\n",
    "        self.train = []\n",
    "        self.test = []\n",
    "        self.classifier = ''\n",
    "        self.chi_sq = chi_sq\n",
    "\n",
    "    def load(self, model, pos, neg, BestFeatureVec=700):\n",
    "        BestFeatureVec = int(BestFeatureVec)\n",
    "        self.pos_origin = json.load(open(pos, 'r'))\n",
    "        self.neg_origin = json.load(open(neg, 'r'))\n",
    "        shuffle(self.pos_origin)\n",
    "        shuffle(self.neg_origin)\n",
    "        poslen = len(self.pos_origin)\n",
    "        neglen = len(self.neg_origin)\n",
    "\n",
    "        # build train and test data.\n",
    "        self.pos_review = self.pos_origin[:int(poslen*0.9)]\n",
    "        self.pos_test = self.pos_origin[int(poslen*0.9):]\n",
    "        self.neg_review = self.neg_origin[:int(neglen*0.9)]\n",
    "        self.neg_test = self.neg_origin[int(neglen*0.9):]\n",
    "\n",
    "        self.bestMainFeatures = create_Mainfeatures(pos_data=self.pos_review, neg_data=self.neg_review, BestFeatureVec=BestFeatureVec, chi_sq=self.chi_sq)\n",
    "        print(self.bestMainFeatures)\n",
    "        # build model\n",
    "        print('start building {} model!!!'.format(model))\n",
    "\n",
    "        self.classifier = SklearnClassifier(self.classifier_table[model]) \n",
    "        if len(self.train) == 0:\n",
    "            print('build training data')\n",
    "            posFeatures = self.emotion_features(self.best_Mainfeatures, self.pos_review, 'pos')\n",
    "            negFeatures = self.emotion_features(self.best_Mainfeatures, self.neg_review, 'neg')\n",
    "            self.train = posFeatures + negFeatures\n",
    "        self.classifier.train(self.train) #訓練分類器\n",
    "\n",
    "    def buildTestData(self, pos_test, neg_test):\n",
    "        pos_test = json.load(open(pos_test, 'r'))\n",
    "        neg_test = json.load(open(neg_test, 'r'))\n",
    "        posFeatures = self.emotion_features(self.best_Mainfeatures, pos_test, 'pos')\n",
    "        negFeatures = self.emotion_features(self.best_Mainfeatures, neg_test, 'neg')\n",
    "        return posFeatures + negFeatures\n",
    "\n",
    "    def best_Mainfeatures(self, word_list):\n",
    "        return {word:True for word in word_list if word in self.bestMainFeatures}\n",
    "\n",
    "    def score(self, pos_test, neg_test):\n",
    "        from sklearn.metrics import precision_recall_curve\n",
    "        from sklearn.metrics import roc_curve\n",
    "        from sklearn.metrics import auc\n",
    "        # build test data set\n",
    "        if len(self.test) == 0:\n",
    "            self.test = self.buildTestData(pos_test, neg_test)\n",
    "\n",
    "        test, test_tag = zip(*self.test)\n",
    "        pred = list(map(lambda x:1 if x=='pos' else 0, self.classifier.classify_many(test))) #對開發測試集的數據進行分類，給出預測的標籤\n",
    "        tag = list(map(lambda x:1 if x=='pos' else 0, test_tag))\n",
    "        # ROC AUC\n",
    "        fpr, tpr, _ = roc_curve(tag, pred, pos_label=1)\n",
    "        print(\"ROC AUC:\" + str(auc(fpr, tpr)))\n",
    "        return auc(fpr, tpr)\n",
    "\n",
    "    def emotion_features(self, feature_extraction_method, data, emo):\n",
    "        return list(map(lambda x:[feature_extraction_method(x), emo], data)) #爲積極文本賦予\"pos\"\n",
    "\n",
    "    def swing(self, sentence):\n",
    "        sentence = self.best_Mainfeatures(CutAndrmStopWords(sentence))\n",
    "        return self.classifier.classify(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg\n",
    "import jieba, os\n",
    "\n",
    "BASEDIR = os.path.dirname('.')\n",
    "stopwords = json.load(open(os.path.join(BASEDIR, 'stopwords', 'stopwords.json'), 'r'))\n",
    "jieba.load_userdict(os.path.join(BASEDIR, 'dictionary', 'dict.txt.big.txt'))\n",
    "jieba.load_userdict(os.path.join(BASEDIR, \"dictionary\", \"NameDict_Ch_v2\"))\n",
    "\n",
    "def CutAndrmStopWords(sentence):\n",
    "    def condition(x):\n",
    "        x = list(x)\n",
    "        word, flag = x[0], x[1]\n",
    "        if len(word) > 1 and flag!='eng' and flag != 'm' and flag !='mq' and word not in stopwords:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    result = filter(condition, pseg.cut(sentence))\n",
    "    result = map(lambda x:list(x)[0], result)\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB V.S. BernoulliNB\n",
    "都是Naive Bayes的一種  \n",
    "差異在於：\n",
    "1. Multinomial 會計算該單字出現再該類別幾次\n",
    "2. Bernoulli 只是計算該單字出現與否而已\n",
    "\n",
    "通常Multinomial會更適合用在Text classification上面\n",
    "\n",
    "## 先用你們今天自己爬下來的資料\n",
    "\n",
    "### 沒有卡方的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Swinger(False)\n",
    "s.load('MultinomialNB', pos='MyPos.json', neg='MyNeg.json', BestFeatureVec=10)\n",
    "s.score(pos_test='MyPos.json', neg_test='MyNeg.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.swing('大停電的夜晚，我很幸運看到了星空')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.swing('XXX 停電害我不能打電動拉')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有卡方的版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Swinger(True)\n",
    "s.load('MultinomialNB', pos='MyPos.json', neg='MyNeg.json', BestFeatureVec=10)\n",
    "s.score(pos_test='pos.json', neg_test='neg.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.swing('大停電的夜晚，我很幸運看到了星空')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.swing('XXX 停電害我不能打電動拉')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用我們從黑特版、黑皮版等等蒐集而來的訓練資料\n",
    "\n",
    "### 沒卡方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Swinger(False)\n",
    "s.load('MultinomialNB', pos='pos.json', neg='neg.json', BestFeatureVec=50)\n",
    "s.score(pos_test='pos.json', neg_test='neg.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.swing('大停電的夜晚，我很幸運看到了星空')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.swing('XXX 停電害我不能打電動拉')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有卡方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Swinger(True)\n",
    "s.load('MultinomialNB', pos='pos.json', neg='neg.json', BestFeatureVec=50)\n",
    "s.score(pos_test='pos.json', neg_test='neg.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.swing('大停電的夜晚，我很幸運看到了星空')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.swing('XXX 停電害我不能打電動拉')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的feature數量對準確度的影響?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "multi = []\n",
    "bernou = []\n",
    "for num in range(10, 50, 10):\n",
    "    s = Swinger(True)\n",
    "    s.load('MultinomialNB', pos='pos.json', neg='neg.json', BestFeatureVec=num)\n",
    "    multi.append(s.score(pos_test='pos.json', neg_test='neg.json'))\n",
    "    \n",
    "    s.load('BernoulliNB', pos='pos.json', neg='neg.json', BestFeatureVec=num)\n",
    "    bernou.append(s.score(pos_test='pos.json', neg_test='neg.json'))\n",
    "\n",
    "plt.plot(range(10, 50, 10), multi, 'o-', color=\"y\",label=\"Multinomial\")\n",
    "plt.plot(range(10, 50, 10), bernou, 'o-', color=\"r\",label=\"Bernoulli\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"features vectors\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (Experimental) with Spark 1.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
