{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字典法的缺點\n",
    "\n",
    "如果以前沒看過這個字  \n",
    "就沒輒了\n",
    "\n",
    "## 讓我們先建立一個語意模型吧 - word2vec\n",
    "\n",
    "![img](https://www.extremetech.com/wp-content/uploads/2015/10/AI-640x353.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將所有的單字透過One hot encoding編碼  \n",
    "送進類神經網路訓練  \n",
    "\n",
    "![img](http://lh3.googleusercontent.com/-Ku4A62Vw5dQ/V4RaKeQaDOI/AAAAAAAACoA/NWmlYfi4-RIuD43knrC2bYCXJmKtQIjTACCo/s565/pic_1.png)\n",
    "\n",
    "接下來教大家如何建立一個word2vec的模型  \n",
    "[github連結](https://github.com/udicatnchu/kem)\n",
    "# KEM\n",
    "\n",
    "訓練Word2Vec model參考文章：[以 gensim 訓練中文詞向量](http://zake7749.github.io/2016/08/28/word2vec-with-gensim/)\n",
    "\n",
    "## Get Started\n",
    "\n",
    "## Installing\n",
    "\n",
    "1. `pip install kem`\n",
    "\n",
    "## Run\n",
    "#### Building the model  \n",
    "使用api前必須先建立model  \n",
    "停用詞以及結巴斷詞的字典在這邊  \n",
    "\n",
    "> 1. 結巴字典：格式是txt, 在 [Open-Sentiment-Training-Data](https://github.com/UDICatNCHU/Open-Sentiment-Training-Data)當中，有數份字典\n",
    "可以依需求將字典合併成一份後再去斷詞，效果會不同。  \n",
    "> 2. 停用詞：有在停用詞裏面的單字會被當作冗詞贅字給濾掉，在此應用中只需要拿 [stopwrds](https://github.com/UDICatNCHU/Open-Sentiment-Training-Data/tree/master/stopwrds)裏面的stopwrds.json即可\n",
    "\n",
    "1. `python manage.py buildkem 結巴自訂字典path 停用詞path 欲訓練model之維度(目前是400維，維度愈大檔案愈大)`\n",
    "\n",
    "#### Usage of KEM class  \n",
    "因為KEM是一個django的函式庫，所以需要設定urls.py以及vies.py  \n",
    "並且在settings.py INSTALLED_APPS 新增kem喔\n",
    "\n",
    "1. settings.py：\n",
    "  ```\n",
    "  INSTALLED_APPS = [\n",
    "      'kem'\n",
    "       ...\n",
    "  ]\n",
    "  ```\n",
    "2. urls.py：  \n",
    "在專案的urls.py引入函式庫的urls.py即可使用該api  \n",
    "  ```\n",
    "  import kem.urls\n",
    "  urlpatterns += [\n",
    "      url(r'^kem/', include(kem.urls))\n",
    "  ]\n",
    "  ```\n",
    "\n",
    "\n",
    "## API\n",
    "1. 取得字的向量：_`/kem`_\n",
    "  - keyword\n",
    "  - num\n",
    "  - example：[http://140.120.13.244:10000/kem?keyword=草履蟲&num=100](http://140.120.13.244:10000/kem?keyword=草履蟲&num=100)\n",
    "\n",
    "  ```\n",
    "  ['原生動物', 0.7895185351371765]\n",
    "  ['藍菌', 0.7865398526191711]\n",
    "  ['甲藻', 0.7792112827301025]\n",
    "  ['藍綠藻', 0.7636655569076538]\n",
    "  ['芽孢', 0.7631546258926392]\n",
    "  ['兼性', 0.7622398138046265]\n",
    "  ['纖毛蟲', 0.7605307102203369]\n",
    "  ['專性', 0.7589520215988159]\n",
    "  ['莢膜', 0.7575902938842773]\n",
    "  ['蟲類', 0.7529693841934204]\n",
    "  ['菌門', 0.7505052089691162]\n",
    "  ['厚壁', 0.75014328956604]\n",
    "  ['厭氧菌', 0.7490075826644897]\n",
    "  ['桿菌屬', 0.7489725947380066]\n",
    "  ['變形蟲', 0.748399555683136]\n",
    "  ['介殼', 0.7460906505584717]\n",
    "  ['節肢動物', 0.7445138692855835]\n",
    "  ['纖毛', 0.744355320930481]\n",
    "  ['革蘭氏', 0.7432918548583984]\n",
    "  ['黴菌', 0.7408658266067505]\n",
    "  ...\n",
    "  etc\n",
    "  ```### 先學一下numpy吧\n",
    "\n",
    "這是一個用C語言去實作的函式庫  \n",
    "讓陣列的記憶體變成連續（python的陣列是用一張記憶體的Table去查詢，速度慢且記憶體位置不連續）  \n",
    "大部份deep learning函式庫都以numpy的nd array為input data的格式\n",
    "\n",
    "* ndarray.ndim\n",
    "    * 回傳這個ndarray的dimension是多少\n",
    "* ndarray.shape\n",
    "    * 用一個tuple表示他是幾乘幾的矩陣\n",
    "* ndarray.size\n",
    "    * 矩陣總共有多少item\n",
    "* ndarray.dtype\n",
    "    * 顯示資料型態。numpy陣列裏面每個元件都要有一樣的資料型態，numpy.int32, numpy.int16, and numpy.float64 are some examples.\n",
    "* ndarray.itemsize\n",
    "    * 顯示每個element佔了幾個bytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先學一下numpy吧\n",
    "\n",
    "這是一個用C語言去實作的函式庫  \n",
    "讓陣列的記憶體變成連續（python的陣列是用一張記憶體的Table去查詢，速度慢且記憶體位置不連續）  \n",
    "大部份deep learning函式庫都以numpy的nd array為input data的格式\n",
    "\n",
    "* ndarray.ndim\n",
    "    * 回傳這個ndarray的dimension是多少\n",
    "* ndarray.shape\n",
    "    * 用一個tuple表示他是幾乘幾的矩陣\n",
    "* ndarray.size\n",
    "    * 矩陣總共有多少item\n",
    "* ndarray.dtype\n",
    "    * 顯示資料型態。numpy陣列裏面每個元件都要有一樣的資料型態，numpy.int32, numpy.int16, and numpy.float64 are some examples.\n",
    "* ndarray.itemsize\n",
    "    * 顯示每個element佔了幾個bytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n",
      "(3, 5)\n",
      "2\n",
      "int32\n",
      "4\n",
      "15\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.arange(15).reshape(3, 5)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.ndim)\n",
    "print(a.dtype.name)\n",
    "print(a.itemsize)\n",
    "print(a.size)\n",
    "print(type(a))\n",
    "b = np.array([6, 7, 8])\n",
    "print(type(b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4]\n",
      "[ 1.2  3.5  5.1]\n",
      "[[ 1.5  2.   3. ]\n",
      " [ 4.   5.   6. ]]\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([2,3,4]))\n",
    "print(np.array([1.2, 3.5, 5.1]))\n",
    "print(np.array([(1.5,2,3), (4,5,6)]))\n",
    "print(np.zeros( (3,4) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 類似python內建的range函式\n",
    "支援小數點  \n",
    "也能指定a~b範圍內切成幾等份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 15 20 25]\n",
      "[ 0.   0.3  0.6  0.9  1.2  1.5  1.8]\n",
      "[ 0.    0.25  0.5   0.75  1.    1.25  1.5   1.75  2.  ]\n"
     ]
    }
   ],
   "source": [
    "print(np.arange( 10, 30, 5 ))\n",
    "print(np.arange( 0, 2, 0.3 ))\n",
    "print(np.linspace( 0, 2, 9 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將一維的陣列  \n",
    "轉換成任意維度的矩陣\n",
    "```\n",
    ">>> a = np.arange(6)                         # 1d array\n",
    ">>> print(a)\n",
    "[0 1 2 3 4 5]\n",
    ">>>\n",
    ">>> b = np.arange(12).reshape(4,3)           # 2d array\n",
    ">>> print(b)\n",
    "[[ 0  1  2]\n",
    " [ 3  4  5]\n",
    " [ 6  7  8]\n",
    " [ 9 10 11]]\n",
    ">>>\n",
    ">>> c = np.arange(24).reshape(2,3,4)         # 3d array\n",
    ">>> print(c)\n",
    "[[[ 0  1  2  3]\n",
    "  [ 4  5  6  7]\n",
    "  [ 8  9 10 11]]\n",
    " [[12 13 14 15]\n",
    "  [16 17 18 19]\n",
    "  [20 21 22 23]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本的矩陣操作 加減乘除\n",
    "```\n",
    ">>> a = np.array( [20,30,40,50] )\n",
    ">>> b = np.arange( 4 )\n",
    ">>> b\n",
    "array([0, 1, 2, 3])\n",
    ">>> c = a-b\n",
    ">>> c\n",
    "array([20, 29, 38, 47])\n",
    ">>> b**2\n",
    "array([0, 1, 4, 9])\n",
    ">>> a<35\n",
    "array([ True, True, False, False], dtype=bool)\n",
    ">>> A = np.array( [[1,1],\n",
    "...             [0,1]] )\n",
    ">>> B = np.array( [[2,0],\n",
    "...             [3,4]] )\n",
    ">>> A*B                         # elementwise product\n",
    "array([[2, 0],\n",
    "       [0, 4]])\n",
    ">>> A.dot(B)                    # matrix product\n",
    "array([[5, 4],\n",
    "       [3, 4]])\n",
    ">>> np.dot(A, B)                # another matrix product\n",
    "array([[5, 4],\n",
    "       [3, 4]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將句子透過word2vec轉換成向量\n",
    "\n",
    "這步驟因為需要很多時間  \n",
    "所以我們已經預處理好  \n",
    "回去時，大家只要透過gensim的API，即可將句子轉換成向量  \n",
    "```\n",
    "from gensim import models\n",
    "model = models.KeyedVectors.load_word2vec_format('med400.model.bin', binary=True)\n",
    "\n",
    "model[單字] # 這樣就能得到該單字的向量\n",
    "```\n",
    "\n",
    "### 透過spark將向量檔轉換成numpy格式\n",
    "\n",
    "<mark style='color:red'>（此block可選擇性閱讀）  </mark>  \n",
    "（因為spark環境不便再課堂上讓所有人操作，所以已經預先將此block的程式執行結果準備好給大家了）  \n",
    "下列程式碼請在spark環境下執行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "conf = pyspark.SparkConf().setAll([('spark.driver.memory', '30g'), ('spark.driver.host', '172.17.0.21'), ('spark.app.id', 'local-1492693477461'), ('spark.rdd.compress', 'True'), ('spark.serializer.objectStreamReset', '100'), ('spark.master', 'local[*]'), ('spark.executor.id', 'driver'), ('spark.submit.deployMode', 'client'), ('spark.driver.port', '39274'), ('spark.app.name', 'PySparkShell')])\n",
    "spark = pyspark.SparkContext(conf=conf)\n",
    "neg_df = spark.read  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')  .option('header', 'true')  .load('neg.csv')\n",
    "pos_df = spark.read  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')  .option('header', 'true')  .load('pos.csv')\n",
    "training_df = neg_df.union(pos_df)\n",
    "\n",
    "def featureExtraction(x):\n",
    "    vector = []\n",
    "    if x[0]==u'p':\n",
    "        vector.append(1)\n",
    "    else:\n",
    "        vector.append(0)\n",
    "    for i in range(1,401):\n",
    "        vector.append(float(x[i]))\n",
    "    return vector\n",
    "\n",
    "train = training_df.rdd.map(featureExtraction).cache()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "train = np.array(train.collect())\n",
    "train.dump('trainData.numpy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一次學類神經網路就上手 -> Keras\n",
    "\n",
    "> pip install keras tensorflow\n",
    "\n",
    "`train_test_split(data[:, 1:], data[:, 0], test_size=0.99, random_state=42)`  \n",
    "意思是說把訓練資料切出99%當作測試資料 1%當作訓練資料  \n",
    "會這樣設計的原因是因為  \n",
    "類神經網路的訓練其實是非常花時間的  \n",
    "上課期間恐怕沒辦法讓各位跑出結果  \n",
    "所以我們調整訓練資料的大小（2000筆）  \n",
    "但是資料太少導致訓練的準確度幾乎是100%正確  \n",
    "現實生活中不太可能發生這種事情  \n",
    "為了避免出現100%，所以將難度提高（只給機器學習1%資料，99%拿去考他）  \n",
    "最後得到 `0.998989898749` 的準確度\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 載入我們預處理好的向量\n",
    "# 將其轉換成numpy型態\n",
    "\n",
    "data = np.load('miniTrainData.numpy')\n",
    "from sklearn.cross_validation import train_test_split\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data[:, 1:], data[:, 0], test_size=0.99, random_state=42)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=400, units=200, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(data_train, labels_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(data_test, labels_test))\n",
    "score, acc = model.evaluate(data_test, labels_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
